{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data set\n",
    "\n",
    "df1 = pd.read_csv(\"archive(1)/combined_data_1.txt\")\n",
    "df2 = pd.read_csv(\"archive(1)/combined_data_2.txt\")\n",
    "df3 = pd.read_csv(\"archive(1)/combined_data_3.txt\")\n",
    "df4 = pd.read_csv(\"archive(1)/combined_data_4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# split the data into training validation and test set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train,val,test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m.6\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)),\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m.8\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)))])\n\u001b[1;32m----> 3\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\n\u001b[0;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m (train\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m13\u001b[39m:])\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TensorDataset(x_train,y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "# split the data into training validation and test set\n",
    "train,val,test = np.split(df.sample(frac=1,random_state=42),[int(.6*len(df)),int(.8*(len(df)))])\n",
    "x_train = (train.iloc[:,:13]).float()\n",
    "y_train = (train.iloc[:,13:]).float()\n",
    "trainer = TensorDataset(x_train,y_train)\n",
    "Trainloader = DataLoader(trainer,batch_size = 32,shuffle = True, drop_last = True)\n",
    "\n",
    "\n",
    "x_val = t.Tensor(val.iloc[:,:13])\n",
    "y_val = t.Tensor(val.iloc[:,13:])\n",
    "validator = TensorDataset(x_val,y_val)\n",
    "valloader = DataLoader(validator,batchsize = validator.tensors[0].shape[0])\n",
    "\n",
    "x_test = t.Tensor(test.iloc[:,:13])\n",
    "y_test = t.Tensor(test.iloc[:,13:])\n",
    "tester = TensorDataset(x_test, y_test)\n",
    "testloader = DataLoader(tester, batchsize = tester.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device to use gpu if available\n",
    "t.device = ('CUDA' if t.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the neural network\n",
    "\n",
    "def classifynet():\n",
    "    \n",
    "    class churnpredNET(nn.modules):\n",
    "        \n",
    "        def __init__(self):\n",
    "            super.__init__()\n",
    "            \n",
    "            # input layer\n",
    "            self.input = nn.Linear(13,100)\n",
    "            \n",
    "            # hidden/fully connected\n",
    "            self.fc1 = nn.Linear(100,100)\n",
    "            self.fc2 = nn.Linear(100,100)\n",
    "            \n",
    "            # output layer\n",
    "            self.output = nn.Linear(100,2)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            x = F.relu(self.input(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc1(x))\n",
    "            return t.log_softmax(self.output(x),axis = 1)\n",
    "        \n",
    "    # model instance\n",
    "    net = churnpredNET()\n",
    "\n",
    "    # loss function\n",
    "    loss = nn.NLLLoss()\n",
    "\n",
    "    # optimiser\n",
    "    optimizer = t.optim.SGD(net.parameters(),lr = .1)\n",
    "    \n",
    "    return net,loss, optimizer\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = classifynet()\n",
    "\n",
    "X,y = iter(train_loader).next()\n",
    "yHat = net(X)\n",
    "\n",
    "# values are log-probability of each number (0-9)\n",
    "# print(torch.exp(yHat))\n",
    "\n",
    "# now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
